import pandas as pd
import numpy as np

df=pd.read_csv("/content/penguins.csv")
df.head(5)

from sklearn.preprocessing import LabelEncoder
encoder=LabelEncoder()
df["species"]=encoder.fit_transform(df["species"])
df.head(10)

X=df[["bill_length_mm","bill_depth_mm","flipper_length_mm","body_mass_g"]].values
y=df["species"].values

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
X=scaler.fit_transform(X)

#we will do one hot encoding for species column 
num_classes=len(np.unique(y))
y_one_hot=np.zeros((y.size,num_classes))
y_one_hot[np.arange(y.size),y]=1

#we split our dataset 
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y_one_hot,test_size=0.2,random_state=42)

#we first randomly initialize our weights and biases then we will adjust them later on
np.random.seed(42)
input_size=X_train.shape[1]
output_size=num_classes
weights=np.random.randn(input_size,output_size)*0.01
biases=np.zeros((1,output_size))

#we will use sigmoid activation function
def softmax(z):
  exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))
  return exp_z / np.sum(exp_z, axis=1, keepdims=True)

def forward_propagation(X,weights,biases):
  z=np.dot(X,weights)+biases
  outcome=softmax(z)
  return outcome


def compute_loss(y_true,y_pred):
  m=y_true.shape[0]
  loss=-np.sum(y_true * np.log(y_pred + 1e-9)) / m
  return loss

def backward_propagation(X,y_true,y_pred,weights,biases,learning_rate):
  m=X.shape[0]
  error=y_pred-y_true
  dw=np.dot(X.T,error)/m
  db=np.sum(error,axis=0,keepdims=True)/m
  weights-=learning_rate*dw
  biases-=learning_rate*db
  return weights,biases

def train_model(X_train,y_train,weights,biases,learning_rate,epochs):
  for epoch in range(epochs):
    y_pred=forward_propagation(X_train,weights,biases)
    loss=compute_loss(y_train,y_pred)
    weights,biases=backward_propagation(X_train,y_train,y_pred,weights,biases,learning_rate)
  return weights,biases

learning_rate=0.01
weights,biases=train_model(X_train,y_train,weights,biases,learning_rate,epochs=1000)

def make_predictions(X,weights,biases):
  y_pred=forward_propagation(X,weights,biases)
  return np.argmax(y_pred,axis=1)

#we check the accuracy of our models 
y_pred_tests=make_predictions(X_test,weights,biases)
#we compare the results with our y_test
y_test_labels=np.argmax(y_test,axis=1)
accuracy=np.mean(y_pred_tests==y_test_labels)*100
print("Accuracy ::",accuracy)
